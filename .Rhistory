webElem <- remDr$findElement(using = "css selector",
value ="tbody tr:nth-child(1) td:nth-child(3)") #relative css selector
webElem$clickElement()
# must tell function to look into .x bcus this searches w/ in specified rows of  table_body2
# instead of exlcuding it and then telling the function to search the entire document?
# map_is superseded meaning it will. not be replaced but there are other syntax recommendations
remDr$goBack()
remDr$open()
remDr$navigate(base_url)
(
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
#working
webElem <- remDr$findElement(using = "css selector",
value ="tbody tr:nth-child(1) td:nth-child(3)") #relative css selector
webElem$clickElement()
#working
activityElem <- remDr$findElement(using = "css selector", # finds the activity link using
value ="tbody tr:nth-child(1) td:nth-child(3)") # relative css selector
#working
activityElem <- remDr$findElement(using = "css selector", # finds the activity link using
value ="tbody tr:nth-child(1) td:nth-child(3)") # relative css selector
#working
activityElem <- remDr$findElement(using = "css selector", # finds the activity link using
value ="tbody tr:nth-child(1) td:nth-child(3)") # relative css selector
activityElem$clickElement()  #clicks the activity link
Sys.sleep(2)
remDr$open()
remDr$navigate(base_url)
rows <- remDr$findElement(using = "css selector", value ="tr") # find all row elements 1st
print(rows)
remDr$rows
rows <- remDr$findElement(using = "css selector", value ="tr") # find all row elements 1st
remDr$open()
base_url <- "https://www.osha.gov/ords/imis/establishment.search?p_logger=1&establishment=&State=CA&officetype=all&Office=950644&sitezip=&p_case=all&p_violations_exist=yes&startmonth=10&startday=14&startyear=2019&endmonth=10&endday=14&endyear=2024"
remDr$navigate(base_url)
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
source <- remDr$getPageSource()[[1]]# read page source from where you navigated
print(links)
# 1: SETUP
remDr$open()
base_url <- "https://www.osha.gov/ords/imis/establishment.search?p_logger=1&establishment=&State=CA&officetype=all&Office=950644&sitezip=&p_case=all&p_violations_exist=yes&startmonth=10&startday=14&startyear=2019&endmonth=10&endday=14&endyear=2024"
remDr$navigate(base_url)
Sys.sleep(3)
remDr$maxWindowSize()
source <- remDr$getPageSource()[[1]]
# 2: PLUG IN SCRAPE OF INITIAL TABLE
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElement(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css selector", valuee = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", valuee = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElement(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
print(rows)
goback()
remDr$goback()
# map_df is superseded meaning it will. not be replaced but there are other syntax recommendations
remDr$goBack()
# map_df is superseded meaning it will. not be replaced but there are other syntax recommendations
remDr$goBack()
# map_df is superseded meaning it will. not be replaced but there are other syntax recommendations
remDr$goBack
# map_df is superseded meaning it will. not be replaced but there are other syntax recommendations
remDr$goBack()
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElements(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElements(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElements(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElements(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
remDr$navigate(base_url)
source <- remDr$getPageSource()[[1]]
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
print(rows)
rows <- remDr$findElements(using = "css selector", value = "tr")
# Getting links: iterate over each row to extract the <a> tag's href attribute
links <- sapply(rows, function(row) {
# Find the <a> element within the row (using relative search)
a_tag <- row$findElement(using = "css selector", value = "td a")
# Extract the href attribute from the <a> tag
a_tag$getElementAttribute("href")
})
# Print extracted links
print(links)
# Print extracted links
print(links)
print(links)
View(links)
printlength((rows))
print(length(rows))
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tr") # find all row elements 1st
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="tbody tr") # find all row elements 1st
print(length(rows))
if (length(rows) > 0) {
first_row <- rows[[1]]
a_tag <- first_row$findElement(using = "css selector", value = "td a")
print(a_tag$getElementAttribute("outerHTML"))  # Print the whole <a> tag
}
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1)") # rows - find all row elements 1st
print(length(rows))
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements 1st
print(length(rows))
links <- sapply(rows, function(row) { # Getting links: iterate over each row to get links
a_tag <- remDr$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href") # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
print(length(rows))
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElement(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
print(length(rows))
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
print(length(rows))
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
print(links)
View(rows)
print(links)
View(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tr") # rows - find all row elements first, its only getting row 1!!!
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
print(links)
source <- remDr$getPageSource()[[1]]
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
View(rows)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
div.row-fluid:nth-child(9) > div:nth-child(2)
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
warnings()
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") # rows - find all row elements first, its only getting row 1!!!
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="/html/body/div[3]/div/header/div[5]/div/div[5]") # rows - find all row elements first, its only getting row 1!!!
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "xpath", value ="/html/body/div[3]/div/header/div[5]/div/div[5]") # rows - find all row elements first, its only getting row 1!!!
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) table tbody tr") # rows - find all row elements first, its only getting row 1!!!
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
rows <- remDr$findElements(using = "css selector", value ="div.table-responsive:nth-child(8) table tbody tr") # rows - find all row elements first, its only getting row 1!!!
links <- sapply(rows, function(row) {   # Getting links: iterate over each row to get links
a_tag <- row$findElement(using = "css", value = "td a")
a_tag$getElementAttribute("href")   # get link itself from <a> (anchor element)
})
print(links)
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
parsed_html <- read_html(source)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
parsed_html <- read_html(source)
links <- parsed_html %>%
html_nodes("div.table-responsive:nth-child(8) > table:nth-child(1) table tbody tr") %>%
html_nodes("td a") %>% # each row has links in <a> tags inside <td>
html_attr("href") # Extract href attributes
print(links)
source <- remDr$getPageSource()[[1]]
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
parsed_html <- read_html(source)
links <- parsed_html %>%
html_nodes("div.table-responsive:nth-child(8) > table:nth-child(1) table tbody") %>%
html_nodes("tr td a") %>% # each row has links in <a> tags inside <td>
html_attr("href") # Extract href attributes
print(links)
View(parsed_html)
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
# Attempt 2 - neither work :( i am sad. 10/16 update, ending web scraping.
parsed_html <- read_html(source)
# 1: SETUP
remDr$open()
View(p0)
base_url <- "https://www.osha.gov/ords/imis/establishment.search?p_logger=1&establishment=&State=CA&officetype=all&Office=950644&sitezip=&p_case=all&p_violations_exist=yes&startmonth=10&startday=14&startyear=2019&endmonth=10&endday=14&endyear=2024"
remDr$navigate(base_url)
remDr$navigate(base_url)
Sys.sleep(3)
remDr$navigate(base_url)
Sys.sleep(3)
remDr$maxWindowSize()
source <- remDr$getPageSource()[[1]]
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
# Attempt 2 - neither work :( i am sad. 10/16 update, ending web scraping.
parsed_html <- read_html(source)
links <- parsed_html %>%
html_nodes("div.table-responsive:nth-child(8) > table:nth-child(1) table tbody tr") %>%
html_nodes("td a") %>% # each row has links in <a> tags inside <td>
html_attr("href") # Extract href attributes
print(links)
# 3: get all links for activity # using for loop, navigate and scrape w/ in them
# Attempt 2 - neither work :( i am sad. 10/16 update, ending web scraping.
parsed_html <- read_html(source)
links <- parsed_html %>%
html_nodes("div.table-responsive:nth-child(8) > table:nth-child(1) tbody tr") %>%
html_nodes("td a href") %>% # each row has links in <a> tags inside <td>
html_attr("href") # Extract href attributes
print(links)
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
remDr$open()
remDr$navigate(base_url)
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
source <- remDr$getPageSource()[[1]]# read page source from where you navigated
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath",
value = "/html/body/div[3]/div/header/div[5]/div/div[6]/a[10]/i")
next_button$clickElement()
next_button$clickElement()
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath",
value = "/html/body/div[3]/div/header/div[5]/div/div[6]/a[10]/i")
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath",
value = "/html/body/div[3]/div/header/div[5]/div/div[6]/a[10]/i")
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@href = "Next Page"]') #cannot use exact xpath
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@href = "Next Page"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa fa-chevron-right = "Next Page"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa fa-chevron-right = "Next Page"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa fa-chevron-right = "Next"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa-chevron-right = "Next"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa-chevron-right = "Next"]') #cannot use exact xpath
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa-chevron-right = "Next Page"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@fa-chevron-right = "Next Page"]') #cannot use exact xpath
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') #cannot use exact xpath
next_button$clickElement()
next_button$clickElement()
errorDetails
errorDetails()
warnings()errorHandler
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') #cannot use exact xpath
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') #cannot use exact xpath
next_button$clickElement()
next_button$clickElement()
next_button$clickElement()
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE ####
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') #cannot use exact xpath
next_button$clickElement()
next_button$clickElement()  #Click next button
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') # locate
next_button$clickElement()  #Click next button
next_button$clickElement()  #Click next button
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') # locate
next_button$clickElement()  #Click next button
Sys.sleep(3)
#str(df) # all chrs
# df <- df %>% select(-1, -2)  # remove first two columns, not sure where/ when to run this prolly after
# everything is scraped
#### NEXT PAGE repeate function ####
repeat {
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') # locate netx button
next_button$clickElement()  # Click next button
Sys.sleep(3)                # Sleep 3 seconds
if (length(remDr$findElements(using = "xpath", value = '//a[@title = "Next Page"]')) == 0) { # a check!
break
}
}
base_url <- "https://www.osha.gov/ords/imis/establishment.search?p_logger=1&establishment=&State=CA&officetype=all&Office=950644&sitezip=&p_case=all&p_violations_exist=yes&startmonth=10&startday=14&startyear=2019&endmonth=10&endday=14&endyear=2024"
remDr$navigate(base_url)
remDr$navigate(base_url)
base_url <- "https://www.osha.gov/ords/imis/establishment.search?p_logger=1&establishment=&State=CA&officetype=all&Office=950644&sitezip=&p_case=all&p_violations_exist=yes&startmonth=10&startday=14&startyear=2019&endmonth=10&endday=14&endyear=2024"
remDr$navigate(base_url)
remDr$open()
remDr$navigate(base_url)
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
#webElem <- remDr$findElement(using = "css selector", value = "div.table-responsive:nth-child(8) > table:nth-child(1)")
# webElem$highlightElement()
remDr$maxWindowSize()
#### Pagination repeat function ####
repeat {
next_button <- remDr$findElement(using = "xpath", value = '//a[@title = "Next Page"]') # locate netx button
next_button$clickElement()  # Click next button
Sys.sleep(2)                # Sleep 3 seconds
if (length(remDr$findElements(using = "xpath", value = '//a[@title = "Next Page"]')) == 0) { # a check!
break
}
}
all_data <- list()
#install.packages("rvest")
#install.packages("pdftools")
#install.packages("xml2")
#install.packages("RSelenium")
#install.packages("binman")
# install.packages("purrr")
library(purrr)
library(pdftools)
library(rvest)
library(httr)
library(xml2)
library(tibble)
library(RSelenium)
library(wdman)
library(binman)
library(dplyr)
errorDetails
#install.packages("rvest")
#install.packages("pdftools")
#install.packages("xml2")
#install.packages("RSelenium")
#install.packages("binman")
# install.packages("purrr")
library(purrr)
library(pdftools)
library(rvest)
library(httr)
library(xml2)
library(tibble)
library(RSelenium)
library(wdman)
library(binman)
library(dplyr)
.20 x 740
.20 * 740
740 -148
library(tigris)
library(sp)
denver_tracts <- tracts(state = "CO", county = 31, cb = TRUE,
class = "sp")
denver_tracts <- tracts(state = "CO", county = 31, cb = TRUE,
class = "sf")
plot(denver_tracts)
ca_county <- counties("CA")
plot(ca_county$geometry)
library(ggplot2)
ggplot(la_tracts) +
geom_sf
ggplot(la_tracts) +
geom_sf()
lac <- tra cts("CA", "los angeles county")
lac <- tracts("CA", "los angeles county")
ggplot(lac) +
geom_sf()
lac <- counties("CA", "los angeles county")
lac <- counties("los angeles")
lac <- counties("los angeles county")
ggplot(lac) +
geom_sf()
lac <- tracts("CA" "los angeles county")
lac <- tracts("CA", "los angeles county")
ggplot(lac) +
geom_sf() + theme_void
ggplot(lac) +
geom_sf() + theme_void()
ggplot(lac) +
geom_sf() + theme_classic()
